{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "THRESHOLD SENSITIVITY\n",
      "1\n",
      "Sensitivity made up of the sum of:\n",
      "15.090735207233916\n",
      "120.72588165787133\n",
      "37.3689807900645\n",
      "Sensitivity made up of the sum of:\n",
      "15.090735207233916\n",
      "120.72588165787133\n",
      "11839.313369780948\n",
      "PROBS (TRAIN,TEST)\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.00278862 0.         0.         0.\n",
      " 0.01514791 0.00183743 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01322604 0.         0.         0.         0.02097333 0.01246938\n",
      " 0.         0.         0.01959236 0.         0.         0.\n",
      " 0.02116402 0.02040868 0.         0.         0.02475652 0.02369674\n",
      " 0.01886321 0.         0.02316314 0.02506728 0.02397889 0.02002259\n",
      " 0.02533902 0.02500134 0.02524304 0.02386349 0.02439305 0.02521404\n",
      " 0.02519898 0.02474392 0.01986628 0.02425632 0.02540311 0.02530868\n",
      " 0.01710092 0.01980678 0.02437619 0.02536623 0.0201986  0.02468141\n",
      " 0.02575617 0.02556604 0.0171257  0.02018913 0.02475074 0.02572995\n",
      " 0.01635339 0.01712468 0.02018994 0.02471117 0.0163283  0.01635567\n",
      " 0.01711544 0.02018616] [0.00968414 0.00868157 0.00788087 0.00721362 0.01132338 0.00956558\n",
      " 0.00845019 0.00758845 0.01271111 0.01132116 0.00959527 0.00854668\n",
      " 0.01325152 0.01277957 0.01135185 0.00971129 0.01261681 0.01238709\n",
      " 0.01204238 0.01194218 0.0129622  0.01258352 0.01226482 0.01201158\n",
      " 0.01319956 0.01290114 0.01239527 0.01222422 0.01329875 0.01321318\n",
      " 0.0129969  0.01261264 0.01326318 0.01326588 0.01322871 0.01314367\n",
      " 0.01332165 0.01330261 0.01320804 0.01323419 0.01334495 0.01332976\n",
      " 0.01330307 0.01327467 0.01332889 0.01334192 0.01333062 0.01330189\n",
      " 0.01334593 0.01334583 0.01334216 0.01333095 0.01333695 0.01334556\n",
      " 0.0133447  0.0133422  0.0132981  0.01333751 0.01334776 0.01334662\n",
      " 0.01326901 0.01329792 0.01333745 0.01334456 0.01330109 0.01333957\n",
      " 0.01334738 0.01334646 0.01326953 0.01330116 0.0133396  0.01334734\n",
      " 0.01326065 0.01326948 0.0133011  0.01333956 0.01326038 0.01326062\n",
      " 0.01326949 0.01330117]\n",
      "SCORES\n",
      "[-1.31005600e+04 -2.55263050e+04 -8.73241299e+04 -8.88403973e+04\n",
      " -4.63897142e+03 -1.19435171e+04 -3.10649578e+04 -5.29165641e+04\n",
      " -9.87370218e+02 -5.85221907e+03 -1.29111303e+04 -2.23961766e+04\n",
      " -2.29629008e+02 -7.95789924e+02 -4.14000140e+03 -1.32023508e+04\n",
      " -1.76887178e+03 -3.69854522e+03 -5.31181289e+03 -2.15039109e+04\n",
      " -1.35209368e+03 -1.51822977e+03 -2.39133825e+03 -4.93166998e+03\n",
      " -3.53339321e+02 -9.53604204e+02 -1.74617530e+03 -3.49489878e+03\n",
      " -1.29264119e+02 -4.31389327e+02 -1.15147395e+03 -1.77395774e+03\n",
      " -1.44093795e+02 -2.01229151e+02 -3.37177208e+02 -3.86188875e+02\n",
      " -9.22004273e+01 -1.36133842e+02 -2.99539684e+02 -6.12895402e+02\n",
      " -7.50003866e+01 -8.68776001e+01 -1.43696193e+02 -2.98992198e+02\n",
      " -9.68133399e+01 -6.90797067e+01 -8.94500607e+01 -1.69006801e+02\n",
      " -6.75777645e+01 -6.78374791e+01 -7.21299850e+01 -9.54092358e+01\n",
      " -8.29107221e+01 -6.47274966e+01 -6.70379542e+01 -6.95007151e+01\n",
      " -1.53163083e+02 -8.24139335e+01 -6.73828767e+01 -6.91974855e+01\n",
      " -2.04793657e+02 -1.52906733e+02 -8.19435479e+01 -6.44778918e+01\n",
      " -1.46943364e+02 -7.76102139e+01 -6.29273602e+01 -6.47350790e+01\n",
      " -2.03895889e+02 -1.46980512e+02 -7.73374798e+01 -6.41978817e+01\n",
      " -2.19837924e+02 -2.03968503e+02 -1.46677951e+02 -7.77005665e+01\n",
      " -2.20457432e+02 -2.19852045e+02 -2.03839588e+02 -1.46781722e+02] [-1.33781746e+04 -2.35985561e+04 -4.79794574e+04 -1.45664372e+05\n",
      " -4.53460716e+03 -1.52810253e+04 -2.24449902e+04 -6.38762286e+04\n",
      " -9.60776619e+02 -5.10016329e+03 -1.33106045e+04 -2.70366508e+04\n",
      " -2.28643822e+02 -8.65558482e+02 -4.71325517e+03 -1.47557408e+04\n",
      " -1.51700508e+03 -3.58071484e+03 -1.47768302e+04 -4.46113885e+03\n",
      " -1.69819154e+03 -2.15678855e+03 -3.01032601e+03 -4.50937311e+03\n",
      " -5.79070524e+02 -7.63159579e+02 -6.24973607e+03 -3.03003412e+03\n",
      " -1.32209403e+02 -2.96294484e+02 -8.57049910e+02 -1.72010741e+03\n",
      " -1.65175018e+02 -2.21990457e+02 -3.72808474e+02 -3.40791841e+02\n",
      " -9.30927162e+01 -1.40962162e+02 -2.20312054e+02 -3.15412766e+02\n",
      " -7.22775788e+01 -1.34171368e+02 -1.51480705e+02 -3.25606700e+02\n",
      " -9.71585081e+01 -7.16836644e+01 -9.19422507e+01 -1.29800970e+02\n",
      " -6.83743065e+01 -6.83759283e+01 -7.36100733e+01 -9.29599735e+01\n",
      " -8.15162293e+01 -6.94017047e+01 -7.02240141e+01 -7.08122652e+01\n",
      " -1.53298864e+02 -8.22680592e+01 -6.65857095e+01 -7.01902960e+01\n",
      " -2.04325554e+02 -1.52809071e+02 -8.13926267e+01 -6.74325156e+01\n",
      " -1.46995544e+02 -7.73009549e+01 -6.30082839e+01 -6.45657586e+01\n",
      " -2.03702222e+02 -1.46801380e+02 -7.84134429e+01 -6.18382022e+01\n",
      " -2.19551130e+02 -2.03850091e+02 -1.46664440e+02 -7.58448922e+01\n",
      " -2.20411977e+02 -2.19996391e+02 -2.03841023e+02 -1.46769398e+02]\n",
      "BEST (TRAIN, TRAIN->TEST)\n",
      "0.4400514697385186 0.4375575273754744\n",
      "SUM PROBS(TRAIN)*-SCORES(TRAIN)\n",
      "0.8474044900517591\n",
      "SUM PROBS(TRAIN)*-SCORES(TEST)\n",
      "0.8658936471489987\n",
      "MEAN SCORES (TRAIN)\n",
      "38.05648371760323\n",
      "MEAN SCORES (TEST)\n",
      "39.9101244529235\n",
      "TEMP_SENS (TRAIN)\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.95564071 0.         0.         0.\n",
      "  0.07850795 0.95564071 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.51091345 0.         0.         0.         0.07209368 0.51091345\n",
      "  0.         0.         0.20920006 0.27294397 0.37055119 0.45820732\n",
      "  0.14302481 0.20920006 0.27294397 0.37055119 0.07110063 0.14302481\n",
      "  0.20920006 0.27294397 0.03675123 0.07110063 0.14302481 0.20920006\n",
      "  0.10385111 0.11293584 0.14393193 0.24511969 0.07469603 0.10385111\n",
      "  0.11293584 0.14393193 0.04234895 0.07469603 0.10385111 0.11293584\n",
      "  0.02421542 0.04234895 0.07469603 0.10385111 0.04666709 0.07807029\n",
      "  0.10827281 0.11869247 0.03572518 0.04666709 0.07807029 0.10827281\n",
      "  0.03138703 0.03572518 0.04666709 0.07807029 0.02271503 0.03138703\n",
      "  0.03572518 0.04666709]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.68744189 0.         0.         0.\n",
      "  0.05900843 0.68744189 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.44164796 0.         0.         0.         0.08069964 0.44164796\n",
      "  0.         0.         0.63394501 0.         0.         0.\n",
      "  0.26795235 0.63394501 0.         0.         0.15619515 0.26795235\n",
      "  0.63394501 0.         0.05306368 0.15619515 0.26795235 0.63394501\n",
      "  0.20776674 0.25080334 0.29910187 0.41929744 0.11747619 0.20776674\n",
      "  0.25080334 0.29910187 0.04699061 0.11747619 0.20776674 0.25080334\n",
      "  0.02395642 0.04699061 0.11747619 0.20776674 0.05184978 0.12159879\n",
      "  0.21073886 0.24693499 0.03580598 0.05184978 0.12159879 0.21073886\n",
      "  0.03132668 0.03580598 0.05184978 0.12159879 0.02268903 0.03132668\n",
      "  0.03580598 0.05184978]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.58147666 0.         0.         0.\n",
      "  0.05890787 0.58147666 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.29215396 0.         0.         0.         0.04745669 0.29215396\n",
      "  0.         0.         0.32453209 0.40468526 0.41423296 0.37574561\n",
      "  0.19357559 0.32453209 0.40468526 0.41423296 0.08506603 0.19357559\n",
      "  0.32453209 0.40468526 0.03153968 0.08506603 0.19357559 0.32453209\n",
      "  0.11360096 0.13367516 0.18393971 0.30721587 0.06922692 0.11360096\n",
      "  0.13367516 0.18393971 0.03608884 0.06922692 0.11360096 0.13367516\n",
      "  0.02285214 0.03608884 0.06922692 0.11360096 0.03983873 0.07166205\n",
      "  0.11559922 0.13317124 0.03360804 0.03983873 0.07166205 0.11559922\n",
      "  0.03093427 0.03360804 0.03983873 0.07166205 0.02265861 0.03093427\n",
      "  0.03360804 0.03983873]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.59968578 0.         0.         0.\n",
      "  0.05259176 0.59968578 0.         0.         0.         0.\n",
      "  0.         0.         0.98570281 0.         0.         0.\n",
      "  0.27342205 0.98570281 0.         0.         0.05243048 0.27342205\n",
      "  0.98570281 0.         0.4161121  0.64913176 0.90504251 0.\n",
      "  0.22392118 0.4161121  0.64913176 0.90504251 0.09751747 0.22392118\n",
      "  0.4161121  0.64913176 0.03119889 0.09751747 0.22392118 0.4161121\n",
      "  0.11716373 0.14526381 0.20115354 0.32751323 0.06978741 0.11716373\n",
      "  0.14526381 0.20115354 0.03414539 0.06978741 0.11716373 0.14526381\n",
      "  0.0217181  0.03414539 0.06978741 0.11716373 0.03772318 0.07233687\n",
      "  0.11821195 0.13682965 0.03179176 0.03772318 0.07233687 0.11821195\n",
      "  0.02935889 0.03179176 0.03772318 0.07233687 0.0215647  0.02935889\n",
      "  0.03179176 0.03772318]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.60768196 0.         0.         0.\n",
      "  0.05683365 0.60768196 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.23081518 0.         0.         0.         0.04190479 0.23081518\n",
      "  0.         0.         0.33859643 0.67668807 0.         0.\n",
      "  0.18182497 0.33859643 0.67668807 0.         0.09511862 0.18182497\n",
      "  0.33859643 0.67668807 0.03429815 0.09511862 0.18182497 0.33859643\n",
      "  0.12200567 0.14569153 0.18274602 0.27080716 0.0751144  0.12200567\n",
      "  0.14569153 0.18274602 0.03676689 0.0751144  0.12200567 0.14569153\n",
      "  0.0218778  0.03676689 0.0751144  0.12200567 0.04058054 0.0777328\n",
      "  0.12357936 0.14163833 0.03243132 0.04058054 0.0777328  0.12357936\n",
      "  0.02946632 0.03243132 0.04058054 0.0777328  0.02156961 0.02946632\n",
      "  0.03243132 0.04058054]]\n",
      "TEMP_SENS (TEST)\n",
      "[[2.35326381e+01 4.73027441e+01 1.14570953e+02 1.74467082e+02\n",
      "  8.51695056e+00 2.35326381e+01 4.73027441e+01 1.14570953e+02\n",
      "  9.55640709e-01 8.51695056e+00 2.35326381e+01 4.73027441e+01\n",
      "  7.85079486e-02 9.55640709e-01 8.51695056e+00 2.35326381e+01\n",
      "  4.28580991e+00 7.60631547e+00 1.10822675e+01 1.41564335e+01\n",
      "  1.86207089e+00 4.28580991e+00 7.60631547e+00 1.10822675e+01\n",
      "  5.10913451e-01 1.86207089e+00 4.28580991e+00 7.60631547e+00\n",
      "  7.20936786e-02 5.10913451e-01 1.86207089e+00 4.28580991e+00\n",
      "  2.09200064e-01 2.72943968e-01 3.70551189e-01 4.58207316e-01\n",
      "  1.43024815e-01 2.09200064e-01 2.72943968e-01 3.70551189e-01\n",
      "  7.11006319e-02 1.43024815e-01 2.09200064e-01 2.72943968e-01\n",
      "  3.67512313e-02 7.11006319e-02 1.43024815e-01 2.09200064e-01\n",
      "  1.03851111e-01 1.12935844e-01 1.43931925e-01 2.45119693e-01\n",
      "  7.46960307e-02 1.03851111e-01 1.12935844e-01 1.43931925e-01\n",
      "  4.23489534e-02 7.46960307e-02 1.03851111e-01 1.12935844e-01\n",
      "  2.42154151e-02 4.23489534e-02 7.46960307e-02 1.03851111e-01\n",
      "  4.66670905e-02 7.80702908e-02 1.08272806e-01 1.18692473e-01\n",
      "  3.57251761e-02 4.66670905e-02 7.80702908e-02 1.08272806e-01\n",
      "  3.13870303e-02 3.57251761e-02 4.66670905e-02 7.80702908e-02\n",
      "  2.27150301e-02 3.13870303e-02 3.57251761e-02 4.66670905e-02]\n",
      " [1.28830674e+01 2.84135385e+01 6.93618246e+01 2.32804677e+02\n",
      "  4.64565083e+00 1.28830674e+01 2.84135385e+01 6.93618246e+01\n",
      "  6.87441893e-01 4.64565083e+00 1.28830674e+01 2.84135385e+01\n",
      "  5.90084272e-02 6.87441893e-01 4.64565083e+00 1.28830674e+01\n",
      "  1.02220003e+01 1.86669705e+01 2.46780730e+01 2.83397529e+01\n",
      "  3.02799870e+00 1.02220003e+01 1.86669705e+01 2.46780730e+01\n",
      "  4.41647959e-01 3.02799870e+00 1.02220003e+01 1.86669705e+01\n",
      "  8.06996368e-02 4.41647959e-01 3.02799870e+00 1.02220003e+01\n",
      "  6.33945008e-01 1.49526690e+00 3.11635366e+00 5.41655530e+00\n",
      "  2.67952348e-01 6.33945008e-01 1.49526690e+00 3.11635366e+00\n",
      "  1.56195146e-01 2.67952348e-01 6.33945008e-01 1.49526690e+00\n",
      "  5.30636767e-02 1.56195146e-01 2.67952348e-01 6.33945008e-01\n",
      "  2.07766745e-01 2.50803336e-01 2.99101871e-01 4.19297441e-01\n",
      "  1.17476191e-01 2.07766745e-01 2.50803336e-01 2.99101871e-01\n",
      "  4.69906135e-02 1.17476191e-01 2.07766745e-01 2.50803336e-01\n",
      "  2.39564161e-02 4.69906135e-02 1.17476191e-01 2.07766745e-01\n",
      "  5.18497784e-02 1.21598791e-01 2.10738862e-01 2.46934991e-01\n",
      "  3.58059757e-02 5.18497784e-02 1.21598791e-01 2.10738862e-01\n",
      "  3.13266781e-02 3.58059757e-02 5.18497784e-02 1.21598791e-01\n",
      "  2.26890283e-02 3.13266781e-02 3.58059757e-02 5.18497784e-02]\n",
      " [8.12024940e+00 2.76970312e+01 8.31017198e+01 2.74438235e+02\n",
      "  2.70039224e+00 8.12024940e+00 2.76970312e+01 8.31017198e+01\n",
      "  5.81476659e-01 2.70039224e+00 8.12024940e+00 2.76970312e+01\n",
      "  5.89078679e-02 5.81476659e-01 2.70039224e+00 8.12024940e+00\n",
      "  2.58694450e+00 4.11304741e+00 5.36732915e+00 6.16675493e+00\n",
      "  1.15343846e+00 2.58694450e+00 4.11304741e+00 5.36732915e+00\n",
      "  2.92153961e-01 1.15343846e+00 2.58694450e+00 4.11304741e+00\n",
      "  4.74566876e-02 2.92153961e-01 1.15343846e+00 2.58694450e+00\n",
      "  3.24532088e-01 4.04685264e-01 4.14232963e-01 3.75745607e-01\n",
      "  1.93575591e-01 3.24532088e-01 4.04685264e-01 4.14232963e-01\n",
      "  8.50660303e-02 1.93575591e-01 3.24532088e-01 4.04685264e-01\n",
      "  3.15396825e-02 8.50660303e-02 1.93575591e-01 3.24532088e-01\n",
      "  1.13600964e-01 1.33675159e-01 1.83939709e-01 3.07215873e-01\n",
      "  6.92269191e-02 1.13600964e-01 1.33675159e-01 1.83939709e-01\n",
      "  3.60888385e-02 6.92269191e-02 1.13600964e-01 1.33675159e-01\n",
      "  2.28521380e-02 3.60888385e-02 6.92269191e-02 1.13600964e-01\n",
      "  3.98387282e-02 7.16620459e-02 1.15599217e-01 1.33171239e-01\n",
      "  3.36080432e-02 3.98387282e-02 7.16620459e-02 1.15599217e-01\n",
      "  3.09342698e-02 3.36080432e-02 3.98387282e-02 7.16620459e-02\n",
      "  2.26586120e-02 3.09342698e-02 3.36080432e-02 3.98387282e-02]\n",
      " [1.21111620e+01 1.68726029e+01 4.81896373e+01 1.02831860e+02\n",
      "  4.74107118e+00 1.21111620e+01 1.68726029e+01 4.81896373e+01\n",
      "  5.99685780e-01 4.74107118e+00 1.21111620e+01 1.68726029e+01\n",
      "  5.25917644e-02 5.99685780e-01 4.74107118e+00 1.21111620e+01\n",
      "  2.29754358e+00 3.89350964e+00 5.47193337e+00 6.84435021e+00\n",
      "  9.85702813e-01 2.29754358e+00 3.89350964e+00 5.47193337e+00\n",
      "  2.73422051e-01 9.85702813e-01 2.29754358e+00 3.89350964e+00\n",
      "  5.24304785e-02 2.73422051e-01 9.85702813e-01 2.29754358e+00\n",
      "  4.16112099e-01 6.49131763e-01 9.05042507e-01 1.15614744e+00\n",
      "  2.23921178e-01 4.16112099e-01 6.49131763e-01 9.05042507e-01\n",
      "  9.75174714e-02 2.23921178e-01 4.16112099e-01 6.49131763e-01\n",
      "  3.11988851e-02 9.75174714e-02 2.23921178e-01 4.16112099e-01\n",
      "  1.17163732e-01 1.45263814e-01 2.01153537e-01 3.27513233e-01\n",
      "  6.97874052e-02 1.17163732e-01 1.45263814e-01 2.01153537e-01\n",
      "  3.41453888e-02 6.97874052e-02 1.17163732e-01 1.45263814e-01\n",
      "  2.17180999e-02 3.41453888e-02 6.97874052e-02 1.17163732e-01\n",
      "  3.77231807e-02 7.23368690e-02 1.18211946e-01 1.36829655e-01\n",
      "  3.17917626e-02 3.77231807e-02 7.23368690e-02 1.18211946e-01\n",
      "  2.93588916e-02 3.17917626e-02 3.77231807e-02 7.23368690e-02\n",
      "  2.15647021e-02 2.93588916e-02 3.17917626e-02 3.77231807e-02]\n",
      " [1.50039109e+01 4.30843875e+01 1.16722733e+02 2.79155485e+02\n",
      "  5.01055542e+00 1.50039109e+01 4.30843875e+01 1.16722733e+02\n",
      "  6.07681963e-01 5.01055542e+00 1.50039109e+01 4.30843875e+01\n",
      "  5.68336514e-02 6.07681963e-01 5.01055542e+00 1.50039109e+01\n",
      "  4.42111977e+00 1.05294596e+01 1.78344057e+01 2.67655518e+01\n",
      "  1.16973488e+00 4.42111977e+00 1.05294596e+01 1.78344057e+01\n",
      "  2.30815179e-01 1.16973488e+00 4.42111977e+00 1.05294596e+01\n",
      "  4.19047938e-02 2.30815179e-01 1.16973488e+00 4.42111977e+00\n",
      "  3.38596434e-01 6.76688069e-01 1.20978376e+00 1.83498381e+00\n",
      "  1.81824971e-01 3.38596434e-01 6.76688069e-01 1.20978376e+00\n",
      "  9.51186230e-02 1.81824971e-01 3.38596434e-01 6.76688069e-01\n",
      "  3.42981514e-02 9.51186230e-02 1.81824971e-01 3.38596434e-01\n",
      "  1.22005669e-01 1.45691531e-01 1.82746017e-01 2.70807159e-01\n",
      "  7.51144018e-02 1.22005669e-01 1.45691531e-01 1.82746017e-01\n",
      "  3.67668915e-02 7.51144018e-02 1.22005669e-01 1.45691531e-01\n",
      "  2.18778020e-02 3.67668915e-02 7.51144018e-02 1.22005669e-01\n",
      "  4.05805450e-02 7.77328003e-02 1.23579364e-01 1.41638328e-01\n",
      "  3.24313246e-02 4.05805450e-02 7.77328003e-02 1.23579364e-01\n",
      "  2.94663250e-02 3.24313246e-02 4.05805450e-02 7.77328003e-02\n",
      "  2.15696109e-02 2.94663250e-02 3.24313246e-02 4.05805450e-02]]\n",
      "SENSITIVITY (TRAIN)\n",
      "173.18559765516972\n",
      "SENSITIVITY (TEST)\n",
      "11975.129986646054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity made up of the sum of:\n",
      "15.090735207233916\n",
      "120.72588165787133\n",
      "30.20884503324782\n",
      "Sensitivity made up of the sum of:\n",
      "15.090735207233916\n",
      "120.72588165787133\n",
      "8381.962362064281\n",
      "PROBS (TRAIN,TEST)\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01900057 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01308705 0.         0.         0.         0.0221629  0.01224895\n",
      " 0.         0.         0.0151157  0.         0.         0.\n",
      " 0.01998146 0.01810423 0.         0.         0.02309915 0.02104119\n",
      " 0.01765164 0.         0.02439285 0.02331836 0.02051087 0.01795061\n",
      " 0.02329046 0.0222507  0.02190655 0.02113723 0.02363774 0.02334253\n",
      " 0.02223368 0.02253851 0.02260968 0.02357752 0.0229691  0.02278048\n",
      " 0.02252982 0.02267996 0.02354357 0.02322363 0.02303946 0.02419346\n",
      " 0.02318508 0.02247151 0.02241547 0.02307497 0.02420555 0.02310077\n",
      " 0.02236103 0.02246959 0.02301258 0.02413963 0.02255491 0.02233581\n",
      " 0.02241118 0.02311231] [0.00882045 0.00777003 0.00711509 0.00663908 0.01090097 0.00912671\n",
      " 0.0078004  0.00702214 0.01287056 0.01083413 0.00902438 0.00786231\n",
      " 0.01342458 0.01285718 0.01092353 0.00917467 0.01269178 0.01207459\n",
      " 0.01211428 0.01181275 0.01276087 0.01262139 0.0121934  0.01197374\n",
      " 0.01334464 0.01303057 0.01261494 0.01237056 0.01347707 0.01331584\n",
      " 0.01309115 0.01254115 0.01341116 0.0132903  0.01324535 0.01325997\n",
      " 0.01346221 0.01342626 0.01335525 0.01330455 0.01348962 0.01345823\n",
      " 0.01340999 0.01334045 0.01349877 0.01348954 0.01345679 0.01340288\n",
      " 0.01348806 0.01347697 0.01347304 0.01345432 0.01349228 0.01348667\n",
      " 0.01348382 0.0134792  0.01348345 0.01349284 0.01348713 0.01348437\n",
      " 0.01347962 0.01348263 0.01349296 0.01348769 0.01348732 0.01349928\n",
      " 0.01348756 0.01348105 0.01347977 0.01348663 0.01349931 0.01348708\n",
      " 0.01347842 0.01347953 0.01348693 0.01349825 0.01348055 0.01347854\n",
      " 0.01348096 0.01348751]\n",
      "SCORES\n",
      "[-1.20914441e+04 -1.79064032e+04 -3.98851544e+04 -9.03111266e+04\n",
      " -1.23375469e+04 -1.21189093e+04 -2.12554486e+04 -4.22801354e+04\n",
      " -8.65197434e+02 -3.81259035e+03 -2.76844466e+04 -3.40912639e+04\n",
      " -1.39611244e+02 -7.52088619e+02 -4.17826700e+03 -1.35506444e+04\n",
      " -9.92064494e+02 -2.51929184e+03 -4.54482853e+03 -6.92549708e+03\n",
      " -6.02931920e+02 -1.11301401e+03 -1.86852860e+03 -4.05536454e+03\n",
      " -2.94323440e+02 -6.86298633e+02 -1.32953719e+03 -3.50202654e+03\n",
      " -8.12979655e+01 -2.79413733e+02 -6.50009198e+02 -1.24127999e+03\n",
      " -1.34601403e+02 -2.17012913e+02 -2.98683957e+02 -5.53947831e+02\n",
      " -1.14767247e+02 -2.23583341e+02 -2.10623280e+02 -2.89995587e+02\n",
      " -6.06329474e+01 -1.01784172e+02 -1.78379297e+02 -2.40853694e+02\n",
      " -4.75492735e+01 -6.43897467e+01 -1.13714167e+02 -1.37819989e+02\n",
      " -5.89957797e+01 -7.07184700e+01 -7.80667935e+01 -1.08361353e+02\n",
      " -5.30423780e+01 -5.56217976e+01 -6.41241772e+01 -7.83245017e+01\n",
      " -6.51395914e+01 -5.46908635e+01 -5.88453909e+01 -6.35788875e+01\n",
      " -7.01013655e+01 -6.58197626e+01 -5.46354553e+01 -6.70685305e+01\n",
      " -6.01354957e+01 -4.61710253e+01 -6.06470609e+01 -6.71146154e+01\n",
      " -7.05286716e+01 -6.10084521e+01 -4.60683449e+01 -5.96959004e+01\n",
      " -7.14882682e+01 -7.08567760e+01 -6.13899294e+01 -4.59382634e+01\n",
      " -6.84677683e+01 -7.16204767e+01 -7.02682622e+01 -6.10386231e+01] [-1.19698753e+04 -4.11231575e+04 -5.97301310e+04 -1.10627710e+05\n",
      " -3.76632179e+03 -1.29302233e+04 -2.01814163e+04 -3.99538766e+04\n",
      " -1.16854409e+03 -5.71948826e+03 -1.04274480e+04 -1.72845347e+04\n",
      " -1.41554480e+02 -7.95929464e+02 -1.00078779e+04 -1.33003606e+04\n",
      " -1.21820054e+03 -1.93119868e+03 -3.54467856e+03 -1.17434986e+04\n",
      " -5.96787019e+02 -1.40615710e+03 -1.95214793e+03 -6.04996605e+03\n",
      " -2.47525819e+02 -3.82223503e+03 -1.42925735e+03 -7.58210361e+03\n",
      " -7.20662941e+01 -2.49563410e+02 -6.09726296e+02 -1.41073483e+03\n",
      " -1.35314761e+02 -2.33857953e+02 -7.98603460e+02 -4.02143317e+02\n",
      " -1.23522504e+02 -1.49086869e+02 -2.30150320e+02 -3.85351752e+02\n",
      " -5.77827116e+01 -9.42151323e+01 -1.55464102e+02 -2.18857450e+02\n",
      " -4.56925551e+01 -5.61256796e+01 -9.34129694e+01 -1.66069628e+02\n",
      " -5.89649744e+01 -7.00482107e+01 -8.01199635e+01 -9.42364778e+01\n",
      " -5.57062429e+01 -5.72628539e+01 -7.18252752e+01 -7.60916695e+01\n",
      " -6.55570496e+01 -5.52428369e+01 -6.03543550e+01 -6.70092340e+01\n",
      " -7.06841801e+01 -6.60365910e+01 -5.56549548e+01 -5.97899112e+01\n",
      " -6.11079764e+01 -4.67327362e+01 -6.28233680e+01 -6.79723807e+01\n",
      " -7.05895221e+01 -6.16352149e+01 -4.60354642e+01 -5.94041090e+01\n",
      " -7.10154738e+01 -7.00584727e+01 -6.11586637e+01 -4.55226871e+01\n",
      " -6.76744720e+01 -7.24771266e+01 -6.89860827e+01 -6.10769472e+01]\n",
      "BEST (TRAIN, TRAIN->TEST)\n",
      "0.3302032883133568 0.3195283574475161\n",
      "SUM PROBS(TRAIN)*-SCORES(TRAIN)\n",
      "0.5637098808960302\n",
      "SUM PROBS(TRAIN)*-SCORES(TEST)\n",
      "0.5423151873879204\n",
      "MEAN SCORES (TRAIN)\n",
      "32.03072026918122\n",
      "MEAN SCORES (TEST)\n",
      "35.699196104059595\n",
      "TEMP_SENS (TRAIN)\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.74733985 0.         0.         0.\n",
      "  0.07481806 0.74733985 0.         0.         0.         0.\n",
      "  0.         0.         0.90407362 0.         0.         0.\n",
      "  0.26560147 0.90407362 0.         0.         0.06226379 0.26560147\n",
      "  0.90407362 0.         0.47058577 0.7685579  0.         0.\n",
      "  0.26732738 0.47058577 0.7685579  0.         0.12474663 0.26732738\n",
      "  0.47058577 0.7685579  0.03498782 0.12474663 0.26732738 0.47058577\n",
      "  0.17403916 0.22987249 0.28063995 0.39054247 0.08374943 0.17403916\n",
      "  0.22987249 0.28063995 0.03767094 0.08374943 0.17403916 0.22987249\n",
      "  0.02271759 0.03767094 0.08374943 0.17403916 0.04177016 0.0869146\n",
      "  0.17648744 0.22543453 0.03378695 0.04177016 0.0869146  0.17648744\n",
      "  0.03057779 0.03378695 0.04177016 0.0869146  0.02234245 0.03057779\n",
      "  0.03378695 0.04177016]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.69696308 0.         0.         0.\n",
      "  0.07103401 0.69696308 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.42403799 0.         0.         0.         0.05736025 0.42403799\n",
      "  0.         0.         0.80454005 0.         0.         0.\n",
      "  0.36714874 0.80454005 0.         0.         0.12452686 0.36714874\n",
      "  0.80454005 0.         0.03636186 0.12452686 0.36714874 0.80454005\n",
      "  0.12658401 0.17637415 0.28857025 0.58793008 0.06839136 0.12658401\n",
      "  0.17637415 0.28857025 0.03687406 0.06839136 0.12658401 0.17637415\n",
      "  0.02303032 0.03687406 0.06839136 0.12658401 0.04030501 0.07033307\n",
      "  0.12577405 0.16517207 0.03379553 0.04030501 0.07033307 0.12577405\n",
      "  0.03061365 0.03379553 0.04030501 0.07033307 0.02235465 0.03061365\n",
      "  0.03379553 0.04030501]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.68585083 0.         0.         0.\n",
      "  0.08052981 0.68585083 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.54845133 0.         0.         0.         0.07499493 0.54845133\n",
      "  0.         0.         0.35521499 0.53719185 0.78093485 0.\n",
      "  0.26406783 0.35521499 0.53719185 0.78093485 0.14007656 0.26406783\n",
      "  0.35521499 0.53719185 0.03804319 0.14007656 0.26406783 0.35521499\n",
      "  0.20076323 0.26623195 0.30780795 0.39156641 0.09062235 0.20076323\n",
      "  0.26623195 0.30780795 0.03769835 0.09062235 0.20076323 0.26623195\n",
      "  0.02260341 0.03769835 0.09062235 0.20076323 0.04189343 0.09407986\n",
      "  0.20414695 0.26590567 0.03365345 0.04189343 0.09407986 0.20414695\n",
      "  0.03053956 0.03365345 0.04189343 0.09407986 0.02233795 0.03053956\n",
      "  0.03365345 0.04189343]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.08232434 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.83467988 0.         0.         0.\n",
      "  0.26243327 0.83467988 0.         0.         0.04982992 0.26243327\n",
      "  0.83467988 0.         0.45798867 0.72460783 0.98073383 0.\n",
      "  0.25030954 0.45798867 0.72460783 0.98073383 0.09667745 0.25030954\n",
      "  0.45798867 0.72460783 0.02985331 0.09667745 0.25030954 0.45798867\n",
      "  0.14065076 0.1891209  0.22789082 0.4278832  0.06494256 0.14065076\n",
      "  0.1891209  0.22789082 0.03467216 0.06494256 0.14065076 0.1891209\n",
      "  0.02254386 0.03467216 0.06494256 0.14065076 0.03813168 0.06737089\n",
      "  0.14336376 0.18902013 0.03319636 0.03813168 0.06737089 0.14336376\n",
      "  0.03048355 0.03319636 0.03813168 0.06737089 0.02233607 0.03048355\n",
      "  0.03319636 0.03813168]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.61900009 0.         0.         0.\n",
      "  0.06142057 0.61900009 0.         0.         0.         0.\n",
      "  0.         0.         0.76218212 0.         0.         0.\n",
      "  0.26653686 0.76218212 0.         0.         0.04686783 0.26653686\n",
      "  0.76218212 0.         0.23867012 0.24907776 0.21487245 0.28595969\n",
      "  0.18551221 0.23867012 0.24907776 0.21487245 0.09718453 0.18551221\n",
      "  0.23867012 0.24907776 0.02820961 0.09718453 0.18551221 0.23867012\n",
      "  0.13415938 0.17436944 0.20585059 0.26631417 0.06666215 0.13415938\n",
      "  0.17436944 0.20585059 0.03273214 0.06666215 0.13415938 0.17436944\n",
      "  0.02142711 0.03273214 0.06666215 0.13415938 0.03641088 0.06924118\n",
      "  0.13619461 0.17238841 0.03139712 0.03641088 0.06924118 0.13619461\n",
      "  0.02890588 0.03139712 0.03641088 0.06924118 0.02126033 0.02890588\n",
      "  0.03139712 0.03641088]]\n",
      "TEMP_SENS (TEST)\n",
      "[[9.36157703e+00 1.81197723e+01 4.48744703e+01 9.75681535e+01\n",
      "  3.94354853e+00 9.36157703e+00 1.81197723e+01 4.48744703e+01\n",
      "  7.47339852e-01 3.94354853e+00 9.36157703e+00 1.81197723e+01\n",
      "  7.48180622e-02 7.47339852e-01 3.94354853e+00 9.36157703e+00\n",
      "  2.73182178e+00 8.00759216e+00 2.08209063e+01 4.67082397e+01\n",
      "  9.04073623e-01 2.73182178e+00 8.00759216e+00 2.08209063e+01\n",
      "  2.65601467e-01 9.04073623e-01 2.73182178e+00 8.00759216e+00\n",
      "  6.22637939e-02 2.65601467e-01 9.04073623e-01 2.73182178e+00\n",
      "  4.70585766e-01 7.68557897e-01 1.13917429e+00 1.61625495e+00\n",
      "  2.67327381e-01 4.70585766e-01 7.68557897e-01 1.13917429e+00\n",
      "  1.24746633e-01 2.67327381e-01 4.70585766e-01 7.68557897e-01\n",
      "  3.49878182e-02 1.24746633e-01 2.67327381e-01 4.70585766e-01\n",
      "  1.74039159e-01 2.29872491e-01 2.80639951e-01 3.90542468e-01\n",
      "  8.37494317e-02 1.74039159e-01 2.29872491e-01 2.80639951e-01\n",
      "  3.76709430e-02 8.37494317e-02 1.74039159e-01 2.29872491e-01\n",
      "  2.27175870e-02 3.76709430e-02 8.37494317e-02 1.74039159e-01\n",
      "  4.17701579e-02 8.69145979e-02 1.76487438e-01 2.25434529e-01\n",
      "  3.37869497e-02 4.17701579e-02 8.69145979e-02 1.76487438e-01\n",
      "  3.05777932e-02 3.37869497e-02 4.17701579e-02 8.69145979e-02\n",
      "  2.23424479e-02 3.05777932e-02 3.37869497e-02 4.17701579e-02]\n",
      " [1.21117884e+01 1.95431503e+01 4.58715688e+01 1.52808026e+02\n",
      "  3.85733255e+00 1.21117884e+01 1.95431503e+01 4.58715688e+01\n",
      "  6.96963082e-01 3.85733255e+00 1.21117884e+01 1.95431503e+01\n",
      "  7.10340124e-02 6.96963082e-01 3.85733255e+00 1.21117884e+01\n",
      "  7.71902499e+00 2.36514095e+01 6.90120770e+01 2.06246868e+02\n",
      "  2.08786743e+00 7.71902499e+00 2.36514095e+01 6.90120770e+01\n",
      "  4.24037994e-01 2.08786743e+00 7.71902499e+00 2.36514095e+01\n",
      "  5.73602465e-02 4.24037994e-01 2.08786743e+00 7.71902499e+00\n",
      "  8.04540046e-01 1.54570662e+00 2.80657323e+00 5.00896074e+00\n",
      "  3.67148740e-01 8.04540046e-01 1.54570662e+00 2.80657323e+00\n",
      "  1.24526862e-01 3.67148740e-01 8.04540046e-01 1.54570662e+00\n",
      "  3.63618607e-02 1.24526862e-01 3.67148740e-01 8.04540046e-01\n",
      "  1.26584009e-01 1.76374153e-01 2.88570254e-01 5.87930077e-01\n",
      "  6.83913593e-02 1.26584009e-01 1.76374153e-01 2.88570254e-01\n",
      "  3.68740650e-02 6.83913593e-02 1.26584009e-01 1.76374153e-01\n",
      "  2.30303234e-02 3.68740650e-02 6.83913593e-02 1.26584009e-01\n",
      "  4.03050083e-02 7.03330723e-02 1.25774046e-01 1.65172068e-01\n",
      "  3.37955286e-02 4.03050083e-02 7.03330723e-02 1.25774046e-01\n",
      "  3.06136494e-02 3.37955286e-02 4.03050083e-02 7.03330723e-02\n",
      "  2.23546508e-02 3.06136494e-02 3.37955286e-02 4.03050083e-02]\n",
      " [1.45377393e+01 2.72065831e+01 8.17446347e+01 3.05118689e+02\n",
      "  5.27933765e+00 1.45377393e+01 2.72065831e+01 8.17446347e+01\n",
      "  6.85850827e-01 5.27933765e+00 1.45377393e+01 2.72065831e+01\n",
      "  8.05298117e-02 6.85850827e-01 5.27933765e+00 1.45377393e+01\n",
      "  3.21864908e+00 4.87860465e+00 6.78113955e+00 8.61409618e+00\n",
      "  1.71331876e+00 3.21864908e+00 4.87860465e+00 6.78113955e+00\n",
      "  5.48451334e-01 1.71331876e+00 3.21864908e+00 4.87860465e+00\n",
      "  7.49949256e-02 5.48451334e-01 1.71331876e+00 3.21864908e+00\n",
      "  3.55214990e-01 5.37191852e-01 7.80934853e-01 1.26362506e+00\n",
      "  2.64067825e-01 3.55214990e-01 5.37191852e-01 7.80934853e-01\n",
      "  1.40076556e-01 2.64067825e-01 3.55214990e-01 5.37191852e-01\n",
      "  3.80431895e-02 1.40076556e-01 2.64067825e-01 3.55214990e-01\n",
      "  2.00763234e-01 2.66231953e-01 3.07807947e-01 3.91566407e-01\n",
      "  9.06223454e-02 2.00763234e-01 2.66231953e-01 3.07807947e-01\n",
      "  3.76983521e-02 9.06223454e-02 2.00763234e-01 2.66231953e-01\n",
      "  2.26034116e-02 3.76983521e-02 9.06223454e-02 2.00763234e-01\n",
      "  4.18934290e-02 9.40798610e-02 2.04146954e-01 2.65905667e-01\n",
      "  3.36534464e-02 4.18934290e-02 9.40798610e-02 2.04146954e-01\n",
      "  3.05395562e-02 3.36534464e-02 4.18934290e-02 9.40798610e-02\n",
      "  2.23379529e-02 3.05395562e-02 3.36534464e-02 4.18934290e-02]\n",
      " [1.80204640e+01 3.75355134e+01 1.02488365e+02 2.36492549e+02\n",
      "  6.37309705e+00 1.80204640e+01 3.75355134e+01 1.02488365e+02\n",
      "  1.06915225e+00 6.37309705e+00 1.80204640e+01 3.75355134e+01\n",
      "  8.23243408e-02 1.06915225e+00 6.37309705e+00 1.80204640e+01\n",
      "  1.54155779e+00 2.47644795e+00 3.34581729e+00 3.79833119e+00\n",
      "  8.34679885e-01 1.54155779e+00 2.47644795e+00 3.34581729e+00\n",
      "  2.62433267e-01 8.34679885e-01 1.54155779e+00 2.47644795e+00\n",
      "  4.98299216e-02 2.62433267e-01 8.34679885e-01 1.54155779e+00\n",
      "  4.57988672e-01 7.24607831e-01 9.80733827e-01 1.16165263e+00\n",
      "  2.50309543e-01 4.57988672e-01 7.24607831e-01 9.80733827e-01\n",
      "  9.66774513e-02 2.50309543e-01 4.57988672e-01 7.24607831e-01\n",
      "  2.98533109e-02 9.66774513e-02 2.50309543e-01 4.57988672e-01\n",
      "  1.40650763e-01 1.89120899e-01 2.27890818e-01 4.27883204e-01\n",
      "  6.49425586e-02 1.40650763e-01 1.89120899e-01 2.27890818e-01\n",
      "  3.46721589e-02 6.49425586e-02 1.40650763e-01 1.89120899e-01\n",
      "  2.25438645e-02 3.46721589e-02 6.49425586e-02 1.40650763e-01\n",
      "  3.81316806e-02 6.73708859e-02 1.43363760e-01 1.89020126e-01\n",
      "  3.31963620e-02 3.81316806e-02 6.73708859e-02 1.43363760e-01\n",
      "  3.04835541e-02 3.31963620e-02 3.81316806e-02 6.73708859e-02\n",
      "  2.23360700e-02 3.04835541e-02 3.31963620e-02 3.81316806e-02]\n",
      " [9.42385577e+00 2.20054263e+01 3.89647611e+01 6.85689121e+01\n",
      "  3.71957143e+00 9.42385577e+00 2.20054263e+01 3.89647611e+01\n",
      "  6.19000092e-01 3.71957143e+00 9.42385577e+00 2.20054263e+01\n",
      "  6.14205697e-02 6.19000092e-01 3.71957143e+00 9.42385577e+00\n",
      "  1.49951657e+00 2.34386818e+00 3.58229022e+00 4.98403031e+00\n",
      "  7.62182116e-01 1.49951657e+00 2.34386818e+00 3.58229022e+00\n",
      "  2.66536864e-01 7.62182116e-01 1.49951657e+00 2.34386818e+00\n",
      "  4.68678281e-02 2.66536864e-01 7.62182116e-01 1.49951657e+00\n",
      "  2.38670117e-01 2.49077757e-01 2.14872454e-01 2.85959691e-01\n",
      "  1.85512210e-01 2.38670117e-01 2.49077757e-01 2.14872454e-01\n",
      "  9.71845283e-02 1.85512210e-01 2.38670117e-01 2.49077757e-01\n",
      "  2.82096120e-02 9.71845283e-02 1.85512210e-01 2.38670117e-01\n",
      "  1.34159383e-01 1.74369437e-01 2.05850587e-01 2.66314171e-01\n",
      "  6.66621477e-02 1.34159383e-01 1.74369437e-01 2.05850587e-01\n",
      "  3.27321353e-02 6.66621477e-02 1.34159383e-01 1.74369437e-01\n",
      "  2.14271105e-02 3.27321353e-02 6.66621477e-02 1.34159383e-01\n",
      "  3.64108823e-02 6.92411830e-02 1.36194606e-01 1.72388412e-01\n",
      "  3.13971240e-02 3.64108823e-02 6.92411830e-02 1.36194606e-01\n",
      "  2.89058837e-02 3.13971240e-02 3.64108823e-02 6.92411830e-02\n",
      "  2.12603328e-02 2.89058837e-02 3.13971240e-02 3.64108823e-02]]\n",
      "SENSITIVITY (TRAIN)\n",
      "166.02546189835306\n",
      "SENSITIVITY (TEST)\n",
      "8517.778978929387\n"
     ]
    }
   ],
   "source": [
    "from dp4gp.utils import dp_normalise, dp_unnormalise\n",
    "from dp4gp import datasets\n",
    "from sklearn.model_selection import KFold\n",
    "import dask_dp4gp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "selection_epsilon = 1.0\n",
    "epsilon = 1.0\n",
    "delta = 0.01\n",
    "\n",
    "\n",
    "####Set up data and parameter search grid\n",
    "kung = datasets.load_kung()\n",
    "sensitivity = 100.0\n",
    "y,ac_sens,norm_params = dp_normalise(kung[kung[:,3]==0,0:1],sensitivity)\n",
    "X = kung[kung[:,3]==0,1:2]\n",
    "\n",
    "#for ls in 5.0**np.linspace(0,4,3):#7\n",
    "#    p_grid[\"lengthscale\"].append(ls)\n",
    "#for v in 5.0**np.linspace(0.0,18.0,5):#10\n",
    "#    p_grid[\"variance\"].append(v)\n",
    "#for nv in 5.0**np.linspace(-3,1,3):#5\n",
    "#    p_grid[\"noisevariance\"].append(nv)    \n",
    "\n",
    "p_grid = {\"lengthscale\":[], 'variance':[], 'noisevariance':[]}\n",
    "for ls in 5.0**np.linspace(0.0,4.0,5):\n",
    "    p_grid[\"lengthscale\"].append(ls)\n",
    "for v in 5.0**np.linspace(0,3,4):\n",
    "    p_grid[\"variance\"].append(v)\n",
    "for nv in 5.0**np.linspace(-1,2,4):\n",
    "    p_grid[\"noisevariance\"].append(nv)    \n",
    "\n",
    "\n",
    "kf = KFold(n_splits=2)\n",
    "probabilities = []\n",
    "allscores = []\n",
    "inducing = None\n",
    "for threshold_sensitivity in [1]:\n",
    "    print(\"=======================================================\")\n",
    "    print(\"THRESHOLD SENSITIVITY\")\n",
    "    print(threshold_sensitivity)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train = X[train_index]\n",
    "        y_train = y[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_test = y[test_index]\n",
    "        probabilities_train,allscores_train,clf_sens_train,clf_sse_train,temp_sens_train, sse_sens_train  = dask_dp4gp.getprobabilities(X_train,y_train,p_grid,5,ac_sens,epsilon=epsilon,delta=delta,selection_epsilon=selection_epsilon,threshold_sensitivity=threshold_sensitivity,errorlimitratio=4.0)\n",
    "        probabilities_test,allscores_test,clf_sens_test,clf_sse_test,temp_sens_test, sse_sens_test  = dask_dp4gp.getprobabilities(X_train,y_train,p_grid,5,ac_sens,epsilon=epsilon,delta=delta,selection_epsilon=selection_epsilon,errorlimitratio=4.0)\n",
    "\n",
    "        print(\"PROBS (TRAIN,TEST)\")\n",
    "        print(probabilities_train,probabilities_test)\n",
    "        print(\"SCORES\")\n",
    "        print(allscores_train,allscores_test)\n",
    "        best_train = np.argmax(probabilities_train)\n",
    "        print(\"BEST (TRAIN, TRAIN->TEST)\")\n",
    "        print(-allscores_train[best_train]/len(X_train),-allscores_test[best_train]/len(X_test))\n",
    "        print(\"SUM PROBS(TRAIN)*-SCORES(TRAIN)\")\n",
    "        print(np.sum(probabilities_train*-allscores_train)/len(X_train))\n",
    "        print(\"SUM PROBS(TRAIN)*-SCORES(TEST)\")\n",
    "        print(np.sum(probabilities_train*-allscores_test)/len(X_train))\n",
    "        print(\"MEAN SCORES (TRAIN)\")\n",
    "        print(np.mean(-allscores_train)/len(X_train))\n",
    "        print(\"MEAN SCORES (TEST)\")\n",
    "        print(np.mean(-allscores_test)/len(X_test))\n",
    "        print(\"TEMP_SENS (TRAIN)\")\n",
    "        print(temp_sens_train)\n",
    "        print(\"TEMP_SENS (TEST)\")\n",
    "        print(temp_sens_test)\n",
    "        print(\"SENSITIVITY (TRAIN)\")\n",
    "        print(sse_sens_train)\n",
    "        print(\"SENSITIVITY (TEST)\")\n",
    "        print(sse_sens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3309454940>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHHFJREFUeJzt3X2QHPWd3/H3d3alw1x4WIsngVjJChwFks8O2oAoUndgsAOOCp2xKZ5Swck5iqugco6TSsBUdI6qLuFydXd2lVW5UziXfVU82kIHwSI82HJxubOwdnVwSGBgrdJKixQQ0sKREsdqd775Y3qG1qhnpme6Z6an+/OqUmm7p7d/v+2t7e/v+WfujoiIFE+p3xkQEZH+UAAQESkoBQARkYJSABARKSgFABGRglIAEBEpKAUAEZGCUgAQESkoBQARkYIa7ncGmjnjjDN82bJl/c6GiMjAmJiYeMfdz4xzbSoBwMy+C6wB3nb3lRGfG/Bt4PPAUeDL7r6z1X2XLVvG+Ph4GlkUESkEM5uKe21aTUDfA65r8vn1wIXBv3XA/0gpXRER6VAqAcDdnweONLlkLfDnXrEdON3MFqeRtoiIdKZXncDnAftDx9PBORER6ZNeBQCLOBe5DrWZrTOzcTMbP3ToUJezJSJSXL0KANPA+aHjJcCBqAvdfZO7j7n72JlnxurIFhGRDvQqADwB/AurWA285+4He5S2iIhESGsY6EPAVcAZZjYN/C6wAMDd/wTYSmUI6CSVYaD/Mo10RSS/JqZm2L7nMKuXL2LV0pGBu3+nepmvVAKAu9/a4nMH7kwjLRHJv4mpGW6/fzuzc2UWDpd44CurU30Zdvv+g5IvLQUhIj0xMTXDxm2TTEzNtLx2+57DzM6VKTscmyuzfc/hVPPS7ft3qtf5yvRSECKSD+2WbFcvX8TC4RLH5sosGC6xevmiVPPT7ft3qtf5UgAQka4Ll2w/PFZm887ppgFg1dIRHvjK6q61hXf7/p3qdb6s0jyfTWNjY661gEQG38TUDLdu+hmz85X3zcLhEg/962y0u+eNmU24+1ica9UHICJNxWm7n5ia4RtbXubeLS9HXrdq6Qg3jX00FWgu1L7dTt+ApEtNQCLSUJy2+/rS/Q8mpiNL9yvOPa32dRkYOXlhZkfjFIVqACJynHCJPM6olO17DnNs/qOm5EbXzRydpRQsClOyynFWRuOkWQsZpBqNagAiOdXJhKL6Evn6NStajkpZvXwRC4asVgNodl3UvaLO9XIyVJq1kEGr0SgAiORQpy+i+hL5zNHZlqNSVi0d4aF1V7B55zQG3HjpkobXRd2r/lyvX6JRtZBO00vzXr2gACCSQ3FeRFGl7KhS+qqlIy1fYnGuaXRd+NzE1Azfeu51PjxWxqnk/bGd02zfc5iRkxcyc3S27RpNq+9Nc+x9VucXNKJhoCI5VC1FV19E9aXoZqXsfq2RE85T2SsdlMPDJXDn2LzjVPoO4tYKqverBpNm35vmz9zvNYbaGQaqGoBIDjVqbqm+nN5894OGNYS4pfm0hWstJYMrLziD8z9+Mg//fF9t85B2mlaq94vzvWn+zP16fp1QABDJqfoXUbiEPTxUYrhkzJc9M00V9c0nX7v21wB4bOc0s8fKlKkEhrj5rd6vk+8tCgUAkZB+V9+7KVzCnp8vc8tlo5x7+se6/rPGfaatOonb6QOoprl+zQpmjs521H9QBAoAIoFBG8IXFuclWy0RfxiUiF9/6/2GI3bSzFecZzoxNdNwFFG7TSrt/h7zHPRb0UQwkUBWJiW1q/rC+8NnXuP2+7c3nIC0aukIX75iGQ64w469M9z8p3/d1QlLcZ5pdSbxgy/s44EX9nHr/2z8M6SVZjjtOM8urxQARALVEvJQim3FvZgV2s4Lb/fBvzvueK5MVwNdnGcadyYxxHue7fweBzXop0VNQCKBtJfi7VWTUjtjz69fuZi/fOOd2vFwia52isZ5pnFnEsd9nu38Hgdt3H7aFABEQtIcwhd3Vmi7bdD117fzwrvt8lEAHtmxj7NOPYmv/uY/TCVPzbR6pnFnErczy7adiWlZ3BegVxQARLokTumykw7LqOvbCVy3XT5aCwTtpNFNcfLfrdL6II3bT5sCgEgH4pSQ45Qu2107phdrzWR1PZt2S+tFHt0TlwKASJvaKSG3Kl3GrSVUx8EfePcDhktWWxrhjbfeZ+O2yY7Wx4n6nompmVoac/OOmTFy8sJY9+2mcJ7vvPqCWNenWYuJemZ5CDAKACJtSrOE3KpUG7WejRm1oZx/8eIBAE5a0N76OI3WAKp+NlQyzKDszoYnd3PROaf07SXXycs8zd9RVPrAwM4ZCdMwUJE2pT1cdNXSEe68+oKmTUTh9WzmyyfeI854943bJtm8c7r2Ypw9VuZbz71eG1J53Etz3pl3MjE8spOhmmn9jsKrk4bTz8vwUdUARNrUy5Ej4dm7jdbtNZq/5KLWAJqbd8rAX02+w469R3jgK6tZvXwRpZJRnj8+paGS9XV4ZCedv2n8jsLPzamUllttZDNoFABE6sTt4O1FlX/V0hHWr1nBpud/yd7DR4HKi+iaS87m74/Ns2LxqZzysQW1F1BUf0DUGkD7jhzlrybfOa4Ee+fVF7Bi8am8NP3ecXm4aez8hj9rL9rBO32ZJ/0dRa1O+rVrf+2ENYoK3wdgZtcB3waGgPvd/b66z78M/AHwZnDqO+5+fxppi6Qpa+sBTUzNsOHJ3czOVdp9SsDCBaUTxu83y3d9CfrGS5cAsGPvkRNKsDf/41Femn65dt/hIatdH5W3Xj2rfgzVjFqdNMkaRVmUOACY2RCwEfgsMA3sMLMn3P2Vuksfcfe7kqYn0k1pdB62UypudW2rUmjUdbMR6/tHlVbXr1nBU7sOcv3KxaxaWtmKceboLF/9jeX8bM9hzj71JP5Ng4lirZ5VWjWDpPdJ8v1FmCSWRg3gMmDS3fcAmNnDwFqgPgCIZF7SyUbhUTtDJWPD2pVcdM4pkS+R+rb5L61awhfrZsG2KoVW7/Pi/ncpB033ZeeEoZtRewNUaxY79h4BqB3HLc03elZp1QyS3ieNfOShlN9MGgHgPGB/6HgauDziui+a2W8ArwP/zt33R1wj0ldJS33b9xyuddjOlZ3//Pguhqzydf1LqL7U/tAL+3hs5/Rx17QzTLSqBMwcnW2Zz3Dp/aldB9uu+TTKW1pDMJPeJ6sT2rIkjQBgEefqByz8L+Ahd//QzL4KfB/4TOTNzNYB6wBGRxtPVxfpliSlvtXLFzFUMuaC4ni5XBltU93gvDpcsDqxKzzCJ3xN3Lbm+mGiRqWPoFXNpb70fv3KxZF9Aq1E5a2TWlTcDerbUfSF3uJIvCm8mV0BfNPd/2lwfA+Au/+3BtcPAUfc/bRW99am8DKIHnxhH+sf30XZneGhyqbm1a0X169ZcVxTy/o1K9h94D1+ML6/dk07TRXhzd+HSsZNY+fH3uSl/qXbr43Ru7lBfR5m67ar15vC7wAuNLNPUBnlcwtwW12GFrv7weDwBuDVFNIVqUnyh572S+K2y0ePa/cHal/XN0vMHJ3l977wSW68dMkJeXjwhX21Ttrw4m31+e20yaq+9N6optHJ82mnFtWsqSZpG3ze2/CTShwA3H3OzO4CnqYyDPS77r7bzDYA4+7+BPBvzewGYA44Anw5aboiVUk6+7o1lDHq5VoV1SxRf/2DL+zjG1sqwzGr6/ffdvlo09VAu6EXQz3VVNM/qcwDcPetwNa6c+tDX98D3JNGWiL1knT29bqjMG6J/aldB084vu3y0dTXuGk0OqnaR/HIjn21PopO0ovTzFSE4ZZZpZnAMnDqXyJJSpBZLX3W79y1YvGpbNw2Wes4Tprf6j68x+adBUPGQ+uuqL2gw4vPhbW7JER97aG+/6N+tJNe/L2nACADpVGTRJJ28F6WPuM2qVTb/J/adZAVi0/lez/be9yLdObobKL8bt45XduCcXbe2bxzmlVLR04YVRTWbEmIKGkMNZXuUgCQgdKoCSRJCbKXpc9WTTjh2k11566N2yZP6Diurokfvr56/ziBoX7sdvV49fJFlMwo140OXBhaQiKutIaaSvcoAMhAyWqTTVzN8t+odhD+nqGhEm+++0FtCefaTOJgo4C5+XidtTdeuoQfTEyfsD7QqqUjbFi7kvWP72K+7JQMrrn47KZLQjQSVbtqNCta+iPxPIBu0jwAiZKlIZ+daJSHjdsm+cNnXqPsMGTw9c9ddFxJ/7Gd0zyyYx9z5crn11x8Ns+9+hZl/6gE75z4ve3mo9Vnkm29ngcg0lOdNtlkZaXPRvlvVjtYtXSEzTunCRYFZd7huVfeYni4xPx8ZRIYZszPt7dmfqOfX52yxaAAIIURZwhlVJv6yMkLE3e6trOJ/Oad05Hrq9SfKwMXn3MKK887rdaEo1K7tEMBQAqjVf9B/eqcuNc2Xy8ZHdca2q15PBZs27i5bmG4Gy9dwqPj+zkW2rHrb6ff47W33q8t/6AXv7RDewJLYVRL2F//3EWRL+H6GkL15Q/J9sZtZ//YZteuWjrCw+uu4PbLR/nUktMwTlxkTqQdqgFIoTQrJdePtsG9tnduKcHm4lE1j0ZNQq1qKdX8hxeBy8poqEZrF0l2aRSQSEgv+gCApk1CcUfgZGmkTnjtIoD/+oVPKgj0iUYBiXSo2SJuad23fmJXO+v/N8trXN0IHI3WLpJsUwAQ6bF+Tmbr1lDY+rWLrl+5OPE9pfsUAER6rH6GLFRqBb1oyunW6qfhtYvUBzA4FABE+qDafBPePawXk9O6Wfuorl0kg0MBQKRPJqZmWP/4rtr+wbMZ2o9AikEBQKRPtu85zHz5o1F4JWtvvf1OacKYVGkimEifrF6+iF9ZUKIEDJeMDWtX6sUsPaUagEifpNUck6X5ADJYFABE+ihpc0xWVjiVwaQmIMmciakZNm6brG16Io21s86QSD3VACRTVKJtz6DvkCb9pQAgmdKtiUp5pWGdkoQCgGRKP0q0/epETStdDeuUTikASKb0ukTbryYnNXVJFigASOb0skTbryYnNXVJFmgUkBRatclpKMGGL4OUrkhYKhvCmNl1wLeBIeB+d7+v7vNfAf4cWAUcBm52972t7qsNYaQXBr0PQCSspxvCmNkQsBH4LDAN7DCzJ9z9ldBlvw3MuPsFZnYL8PvAzUnTlvzo58uwX52o6ryVfkujD+AyYNLd9wCY2cPAWiAcANYC3wy+/iHwHTMzz/J+lNIz6hAV6Y80+gDOA/aHjqeDc5HXuPsc8B4Q2ehpZuvMbNzMxg8dOpRC9iTrNJtVpD/SCAAWca6+ZB/nmspJ903uPubuY2eeeWbizEn2qUNUpD/SaAKaBs4PHS8BDjS4ZtrMhoHTgCMppC091o22es1mFemPNALADuBCM/sE8CZwC3Bb3TVPAHcAPwO+BPxE7f+Dp5tt9eoQFem9xE1AQZv+XcDTwKvAo+6+28w2mNkNwWV/Biwys0ng68DdSdOV3lNbvUi+pDIT2N23Alvrzq0Pff33wE1ppCX9o5UnRfJFS0FIbGqrF8kXBQA5TqtOXrXVi+SHAoDUaEKWSLFoMTipUSevSLEoAEiNJmSJFIuagKRGnbwixaIAICd0/Kb54teSxyLZpQBQcN3s+FWnski2qQ+g4OJ0/E5MzbBx2yQTUzOp31tE+kc1gIJrNbs3SSleM4dFsk0BoOBadfwm2bxcncoi2aYAIE07fpOW4jVzWCS7FACkKZXiRfJLAUBaUileJJ80CkhEpKAUAERECkoBQESkoBQA5ASdTvwSkcGiTmCpmZia4bGd0/xgfD9zZdfyDSI5pwAgwEczfj88VsaDc+1O/BKRwaImoIzrVXNMdcZv9eVvaE8AkbxTDSDDermaZnjG79BQiS+tWsIXL12i0r9IjikAZFiSdXjapRm/IsWjAJBhvV5NUzN+RYpFASDDVCoXkW5SAMg4lcpFpFsSjQIys4+b2bNm9kbwf+SbyszmzezF4N8TSdIUEZF0JB0GejfwY3e/EPhxcBzlA3f/dPDvhoRpSgTN3hWRdiVtAloLXBV8/X3gp8B/SnhPaZM2XxeRTiStAZzt7gcBgv/PanDdSWY2bmbbzey3EqYpdbT5uoh0omUNwMyeA86J+OjeNtIZdfcDZrYc+ImZvezuv2yQ3jpgHcDo6GgbSRSXNl8XkU6Yu7e+qtE3m70GXOXuB81sMfBTd7+oxfd8D3jS3X/Y6v5jY2M+Pj7ecf6KZGJqpuVw0TjXiMhgM7MJdx+Lc23SPoAngDuA+4L/H4/IzAhw1N0/NLMzgCuB/54wXanTario+glEpF7SPoD7gM+a2RvAZ4NjzGzMzO4PrrkYGDezl4BtwH3u/krCdKVN6icQkXqJagDufhi4JuL8OPCV4Ou/Bj6ZJB1JTv0EIlJPM4ELQstKiEg9BYABk6QjV8tKiEiYAsAAUUeuiKRJO4INEHXkikiaFAAGSLUjd8i0XaOIJKcmoAGijlwRSZMCwIAJd+RqZq+IJKEAMKDUISwiSakPYECpQ1hEklIAGFDqEBaRpNQENKDUISwiSSkADDDN7BWRJNQEJCJSUAoAOaaN4kWkGTUB5ZSGiYpIK6oB5JSGiYpIKwoAOaVhoiLSipqAckrDREWkFQWAHNMwURFpRk1AIiIFpQAgIlJQCgAiIgWlACAiUlAKACIiBaUA0AVJlmDQ8g0i0isaBpqyJEswaPkGEemlRDUAM7vJzHabWdnMxppcd52ZvWZmk2Z2d5I0sy7JEgxavkFEeilpE9Au4Ebg+UYXmNkQsBG4HrgEuNXMLkmYbmZFLcEQt1lHyzeISC8lagJy91cBzKzZZZcBk+6+J7j2YWAt8EqStLOqfgkGIHazjpZvEJFe6kUfwHnA/tDxNHB5D9Ltm/ASDBu3TZ7QrNPsxa7lG0SkV1oGADN7Djgn4qN73f3xGGlEVQ+8SXrrgHUAo6OjMW6fbdVmnWNzZTXriEimtAwA7n5twjSmgfNDx0uAA03S2wRsAhgbG2sYKAaFmnVEJKt60QS0A7jQzD4BvAncAtzWg3QzQ806IpJFSYeBfsHMpoErgB+Z2dPB+XPNbCuAu88BdwFPA68Cj7r77mTZFhGRpJKOAtoCbIk4fwD4fOh4K7A1SVqDbGJqRk1AIpI5mgncZZrdKyJZpbWAukyze0UkqxQAukyze0Ukq9QE1KZW7fn1n2sYqIhklQJAG1q15zf6XMNARSSL1ATUhlbt+WrvF5FBogDQhlbt+WrvF5FBYu7ZXW1hbGzMx8fH+52N47TbByAi0ktmNuHuDfdnCVMfQJ1WL/BW7flq7xeRQaEAEKJJWyJSJOoDCFEnrogUiQJASLgTd6hkHHj3g5bbOIqIDCoFgJDqpK2bLxsFMx76+T5uv3+7goCI5JICQJ1VS0c47/SPMTevpiARyTcFgAgazy8iRaBRQBG0fo+IFIECQAMazy8ieacmIBGRglIAEBEpKAUAEZGCUgAQESkoBQARkYJSABARKSgNA60TXg4a0FwAEcktBYCQ8HLQw0MlcGeu7FoaWkRySU1AIfXLQR+bd60HJCK5pRpASHUNoGNzZYaCGsB82bUekIjkUqIAYGY3Ad8ELgYuc/fIDXzNbC/wPjAPzMXdr7LX6tcAeu3/vs9Tuw5y/crFav4RkdxJWgPYBdwI/GmMa69293cSptd11TWAJqZm2PDkbmbnyuzYe4SLzjlFQUBEciVRH4C7v+rur6WVmSzR9pAikne96gR24BkzmzCzdc0uNLN1ZjZuZuOHDh3qUfZOpD0BRCTvWjYBmdlzwDkRH93r7o/HTOdKdz9gZmcBz5rZL9z9+agL3X0TsAlgbGzMY94/ddoTQETyrmUAcPdrkybi7geC/982sy3AZUBkAMiC8GSwO6++oN/ZERHpiq4PAzWzXwVK7v5+8PXngA3dTrdT4clgmgAmInmWqA/AzL5gZtPAFcCPzOzp4Py5ZrY1uOxs4P+Y2UvAz4Efufv/TpJuN8Xt/J2YmmHjtkkmpmZ6nEMRkXQkqgG4+xZgS8T5A8Dng6/3AJ9Kkk4vhSeDNer8VS1BRPJAM4HrxOn8jaolKACIyKBRAIjQakP4OLUEEZGsUwDogIaIikgeKAB0qFUtQUQk67QctIhIQRUyAGgIp4hIAZuANIRTRKSicDUArfIpIlJRuACgVT5FRCoK1wSkIZwiIhWFCwCgIZwiIlDAJiAREalQABARKSgFABGRglIAEBEpKAUAEZGCUgAQESkoBQARkYJSABARKahcBgCt9iki0lruZgJrtU8RkXhyVwPQap8iIvHkLgBotU8RkXhy1wSk1T5FROLJXQAArfYpIhJH7pqAREQknkQBwMz+wMx+YWZ/a2ZbzOz0BtddZ2avmdmkmd2dJE0REUlH0hrAs8BKd/914HXgnvoLzGwI2AhcD1wC3GpmlyRMV0REEkoUANz9GXefCw63A0siLrsMmHT3Pe4+CzwMrE2SroiIJJdmH8C/Ap6KOH8esD90PB2cExGRPmo5CsjMngPOifjoXnd/PLjmXmAOeCDqFhHnvEl664B1AKOjo62yJyIiHWoZANz92mafm9kdwBrgGnePerFPA+eHjpcAB5qktwnYFNz7kJlNtcpjyBnAO21cn0d6BhV6DhV6DhVFeg5L415o0e/smN9sdh3wR8BvuvuhBtcMU+kgvgZ4E9gB3ObuuztOuHF+xt19LO37DhI9gwo9hwo9hwo9h2hJ+wC+A5wCPGtmL5rZnwCY2blmthUg6CS+C3gaeBV4tBsvfxERaU+imcDufkGD8weAz4eOtwJbk6QlIiLpyttM4E39zkAG6BlU6DlU6DlU6DlESNQHICIigytvNQAREYlpIAOAmX3XzN42s12hcx83s2fN7I3g/9wvB2pm55vZNjN71cx2m9nvBOcL9SzM7CQz+7mZvRQ8h/8SnP+Emb0QPIdHzGxhv/PabWY2ZGZ/Y2ZPBsdFfAZ7zezlYGDKeHCuUH8TcQ1kAAC+B1xXd+5u4MfufiHw4+A47+aAf+/uFwOrgTuDdZaK9iw+BD7j7p8CPg1cZ2argd8H/jh4DjPAb/cxj73yO1RG21UV8RkAXO3unw4N/Sza30QsAxkA3P154Ejd6bXA94Ovvw/8Vk8z1QfuftDddwZfv0/lD/88CvYsvOL/BYcLgn8OfAb4YXA+98/BzJYA/wy4Pzg2CvYMmijU30RcAxkAGjjb3Q9C5cUInNXn/PSUmS0D/hHwAgV8FkHTx4vA21RWqf0l8G5oscIirEH1LeA/AuXgeBHFewZQCf7PmNlEsLQMFPBvIo5c7ghWNGb2D4DNwNfc/e8qBb9icfd54NPBnhRbgIujLuttrnrHzNYAb7v7hJldVT0dcWlun0HIle5+wMzOojJJ9Rf9zlBW5akG8JaZLQYI/n+7z/npCTNbQOXl/4C7PxacLuSzAHD3d4GfUukTOT1YigRarEGVA1cCN5jZXipLrn+GSo2gSM8AqE1Exd3fplIYuIwC/000k6cA8ARwR/D1HcDjfcxLTwRtvH8GvOrufxT6qFDPwszOrO5GZ2YfA66l0h+yDfhScFmun4O73+PuS9x9GXAL8BN3v50CPQMAM/tVMzul+jXwOWAXBfubiGsgJ4KZ2UPAVVRW+HsL+F3gL4BHgVFgH3CTu9d3FOeKmf0T4C+Bl/mo3fcbVPoBCvMszOzXqXTsDVEp1Dzq7hvMbDmV0vDHgb8B/rm7f9i/nPZG0AT0H9x9TdGeQfDzbgkOh4EH3f33zGwRBfqbiGsgA4CIiCSXpyYgERFpgwKAiEhBKQCIiBSUAoCISEEpAIiIFJQCgIhIQSkAiIgUlAKAiEhB/X+BBx2CEYC3YgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(X_train,y_train,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBS\n",
    "[4.96166171e-04 1.13249232e-01 3.78181427e-01 5.08073175e-01]\n",
    "SCORES\n",
    "[-5818.0539936  -1280.66263656  -299.16530255   -99.27198396]\n",
    "SUM PROBS*-SCORES\n",
    "1.085355312567357\n",
    "MEAN SCORES\n",
    "6.530621878640797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import GPy\n",
    "%matplotlib inline\n",
    "plt.plot(X,y,'.')\n",
    "k = GPy.kern.RBF(1)\n",
    "m = GPy.models.GPRegression(X,y,k)\n",
    "#m.kern.variance.fix(10000)# = 100.0\n",
    "m.kern.lengthscale.fix(5**4)\n",
    "m.optimize()\n",
    "m.plot()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\begin{center}\n",
      "\\begin{tabular}{ c c c c }\n",
      "\n",
      "Lengthscale & Noise variance & Kernel variance & Probability & RMSE \\\\ \n",
      "  \\hline\n",
      "1.0 & 0.2 & 1.0 & 0.0000 & 235.52 \\\\\n",
      "1.0 & 0.2 & 5.0 & 0.0000 & 436.54 \\\\\n",
      "1.0 & 0.2 & 25.0 & 0.0000 & 526.11 \\\\\n",
      "1.0 & 0.2 & 125.0 & 0.0000 & 715.99 \\\\\n",
      "1.0 & 1.0 & 1.0 & 0.0000 & 132.11 \\\\\n",
      "1.0 & 1.0 & 5.0 & 0.0000 & 244.78 \\\\\n",
      "1.0 & 1.0 & 25.0 & 0.0000 & 305.81 \\\\\n",
      "1.0 & 1.0 & 125.0 & 0.0000 & 430.29 \\\\\n",
      "1.0 & 5.0 & 1.0 & 0.0000 & 73.59 \\\\\n",
      "1.0 & 5.0 & 5.0 & 0.0000 & 162.80 \\\\\n",
      "1.0 & 5.0 & 25.0 & 0.0000 & 219.82 \\\\\n",
      "1.0 & 5.0 & 125.0 & 0.0000 & 283.01 \\\\\n",
      "1.0 & 25.0 & 1.0 & 0.0190 & 25.61 \\\\\n",
      "1.0 & 25.0 & 5.0 & 0.0000 & 60.73 \\\\\n",
      "1.0 & 25.0 & 25.0 & 0.0000 & 215.35 \\\\\n",
      "1.0 & 25.0 & 125.0 & 0.0000 & 248.26 \\\\\n",
      "5.0 & 0.2 & 1.0 & 0.0000 & 75.13 \\\\\n",
      "5.0 & 0.2 & 5.0 & 0.0000 & 94.60 \\\\\n",
      "5.0 & 0.2 & 25.0 & 0.0000 & 128.16 \\\\\n",
      "5.0 & 0.2 & 125.0 & 0.0000 & 233.28 \\\\\n",
      "5.0 & 1.0 & 1.0 & 0.0000 & 52.59 \\\\\n",
      "5.0 & 1.0 & 5.0 & 0.0000 & 80.72 \\\\\n",
      "5.0 & 1.0 & 25.0 & 0.0000 & 95.11 \\\\\n",
      "5.0 & 1.0 & 125.0 & 0.0000 & 167.44 \\\\\n",
      "5.0 & 5.0 & 1.0 & 0.0131 & 33.87 \\\\\n",
      "5.0 & 5.0 & 5.0 & 0.0000 & 133.09 \\\\\n",
      "5.0 & 5.0 & 25.0 & 0.0000 & 81.38 \\\\\n",
      "5.0 & 5.0 & 125.0 & 0.0000 & 187.44 \\\\\n",
      "5.0 & 25.0 & 1.0 & 0.0222 & 18.27 \\\\\n",
      "5.0 & 25.0 & 5.0 & 0.0122 & 34.01 \\\\\n",
      "5.0 & 25.0 & 25.0 & 0.0000 & 53.16 \\\\\n",
      "5.0 & 25.0 & 125.0 & 0.0000 & 80.85 \\\\\n",
      "25.0 & 0.2 & 1.0 & 0.0151 & 25.04 \\\\\n",
      "25.0 & 0.2 & 5.0 & 0.0000 & 32.92 \\\\\n",
      "25.0 & 0.2 & 25.0 & 0.0000 & 60.83 \\\\\n",
      "25.0 & 0.2 & 125.0 & 0.0000 & 43.17 \\\\\n",
      "25.0 & 1.0 & 1.0 & 0.0200 & 23.92 \\\\\n",
      "25.0 & 1.0 & 5.0 & 0.0181 & 26.28 \\\\\n",
      "25.0 & 1.0 & 25.0 & 0.0000 & 32.66 \\\\\n",
      "25.0 & 1.0 & 125.0 & 0.0000 & 42.26 \\\\\n",
      "25.0 & 5.0 & 1.0 & 0.0231 & 16.36 \\\\\n",
      "25.0 & 5.0 & 5.0 & 0.0210 & 20.89 \\\\\n",
      "25.0 & 5.0 & 25.0 & 0.0177 & 26.84 \\\\\n",
      "25.0 & 5.0 & 125.0 & 0.0000 & 31.85 \\\\\n",
      "25.0 & 25.0 & 1.0 & 0.0244 & 14.55  *\\\\\n",
      "25.0 & 25.0 & 5.0 & 0.0233 & 16.13 \\\\\n",
      "25.0 & 25.0 & 25.0 & 0.0205 & 20.81 \\\\\n",
      "25.0 & 25.0 & 125.0 & 0.0180 & 27.74 \\\\\n",
      "125.0 & 0.2 & 1.0 & 0.0233 & 16.53 \\\\\n",
      "125.0 & 0.2 & 5.0 & 0.0223 & 18.02 \\\\\n",
      "125.0 & 0.2 & 25.0 & 0.0219 & 19.27 \\\\\n",
      "125.0 & 0.2 & 125.0 & 0.0211 & 20.90 \\\\\n",
      "125.0 & 1.0 & 1.0 & 0.0236 & 16.07 \\\\\n",
      "125.0 & 1.0 & 5.0 & 0.0233 & 16.29 \\\\\n",
      "125.0 & 1.0 & 25.0 & 0.0222 & 18.24 \\\\\n",
      "125.0 & 1.0 & 125.0 & 0.0225 & 18.78 \\\\\n",
      "125.0 & 5.0 & 1.0 & 0.0226 & 17.43 \\\\\n",
      "125.0 & 5.0 & 5.0 & 0.0236 & 16.00 \\\\\n",
      "125.0 & 5.0 & 25.0 & 0.0230 & 16.72 \\\\\n",
      "125.0 & 5.0 & 125.0 & 0.0228 & 17.62 \\\\\n",
      "125.0 & 25.0 & 1.0 & 0.0225 & 18.10 \\\\\n",
      "125.0 & 25.0 & 5.0 & 0.0227 & 17.49 \\\\\n",
      "125.0 & 25.0 & 25.0 & 0.0235 & 16.06 \\\\\n",
      "125.0 & 25.0 & 125.0 & 0.0232 & 16.65 \\\\\n",
      "625.0 & 0.2 & 1.0 & 0.0230 & 16.83 \\\\\n",
      "625.0 & 0.2 & 5.0 & 0.0242 & 14.72 \\\\\n",
      "625.0 & 0.2 & 25.0 & 0.0232 & 17.06 \\\\\n",
      "625.0 & 0.2 & 125.0 & 0.0225 & 17.75 \\\\\n",
      "625.0 & 1.0 & 1.0 & 0.0224 & 18.09 \\\\\n",
      "625.0 & 1.0 & 5.0 & 0.0231 & 16.90 \\\\\n",
      "625.0 & 1.0 & 25.0 & 0.0242 & 14.61 \\\\\n",
      "625.0 & 1.0 & 125.0 & 0.0231 & 16.59 \\\\\n",
      "625.0 & 5.0 & 1.0 & 0.0224 & 18.14 \\\\\n",
      "625.0 & 5.0 & 5.0 & 0.0225 & 18.02 \\\\\n",
      "625.0 & 5.0 & 25.0 & 0.0230 & 16.83 \\\\\n",
      "625.0 & 5.0 & 125.0 & 0.0241 & 14.52 \\\\\n",
      "625.0 & 25.0 & 1.0 & 0.0226 & 17.71 \\\\\n",
      "625.0 & 25.0 & 5.0 & 0.0223 & 18.33 \\\\\n",
      "625.0 & 25.0 & 25.0 & 0.0224 & 17.88 \\\\\n",
      "625.0 & 25.0 & 125.0 & 0.0231 & 16.82 \\\\\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\\caption{Hyperparameter search using the exponential mechanism. }\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\\begin{table}\\n\\\\begin{center}\\n\\\\begin{tabular}{ c c c c }\\n\")\n",
    "print(\"Lengthscale & Noise variance & Kernel variance & Probability & RMSE \\\\\\\\ \\n  \\\\hline\")\n",
    "for i,(param,prob,score) in enumerate(zip(clf_sse_train.cv_results_['params'],probabilities_train,allscores_test)):\n",
    "    if i == best_train:\n",
    "        a=\" *\"\n",
    "    else:\n",
    "        a = \"\"\n",
    "    print(\"%0.1f & %0.1f & %0.1f & %0.4f & %0.2f %s\\\\\\\\\" % (param['lengthscale'],param['noisevariance'],param['variance'],prob,norm_params['std']*np.sqrt(-score/len(X_test)),a))\n",
    "print(\"\\\\end{tabular}\\n\\\\end{center}\\n\\\\caption{Hyperparameter search using the exponential mechanism. }\\n\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST (TRAIN, TRAIN->TEST)\n",
      "14.792292897307496 14.551223257280054\n",
      "SUM PROBS(TRAIN)*-SCORES(TRAIN)\n",
      "19.327363925856304\n",
      "SUM PROBS(TRAIN)*-SCORES(TEST)\n",
      "19.023214784418712\n",
      "MEAN TEST SCORES\n",
      "153.80626249376118\n"
     ]
    }
   ],
   "source": [
    "print(\"BEST (TRAIN, TRAIN->TEST)\")\n",
    "print(norm_params['std']*np.sqrt(-allscores_train[best_train]/len(X_train)),norm_params['std']*np.sqrt(-allscores_test[best_train]/len(X_test)))\n",
    "print(\"SUM PROBS(TRAIN)*-SCORES(TRAIN)\")\n",
    "print(norm_params['std']*np.sqrt(np.sum(probabilities_train*-allscores_train)/len(X_train)))\n",
    "print(\"SUM PROBS(TRAIN)*-SCORES(TEST)\")\n",
    "print(norm_params['std']*np.sqrt(np.sum(probabilities_train*-allscores_test)/len(X_test)))\n",
    "print(\"MEAN TEST SCORES\")\n",
    "print(norm_params['std']*np.sqrt(np.mean(-allscores_test)/len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.80000000000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8*len(X)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sse.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_sse.best_estimator_.dpgp.model.kern.lengthscale = 1\n",
    "clf_sse.best_estimator_.dpgp.plot()\n",
    "plt.ylim([-1.5,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "clf_sse.best_estimator_.dpgp.plot()\n",
    "plt.ylim([-1.5,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "import GPy\n",
    "from dp4gp import dp4gp\n",
    "\n",
    "ac_sens = 2.0\n",
    "#X = 1.0*np.arange(0,40)[:,None]\n",
    "#X+=np.random.randn(X.shape[0])[:,None]*1e-4\n",
    "#X = np.c_[X,X]\n",
    "#y = np.sin(X[:,0:1])+np.random.randn(40,1)\n",
    "\n",
    "kern = GPy.kern.RBF(1)\n",
    "kern.lengthscale=8\n",
    "model = GPy.models.GPRegression(X,y,kern,normalizer=None)\n",
    "model.Gaussian_noise = 1.0\n",
    "kern.variance = 1.0\n",
    "dpgp = dp4gp.DPGP_cloaking(model,ac_sens,epsilon,delta)\n",
    "dpgp.plot()\n",
    "plt.ylim([-1.5,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dp4gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "GPy.models.SparseGPRegression(np.arange(0,10)[:,None],np.arange(0,10)[:,None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the trade off for:\n",
    "\n",
    " - size of x-validation vs sensitivity\n",
    " - ratio of epsilon used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0,6)[:,None]\n",
    "y = np.sin(X/10) #np.ones([10,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X,y,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = GPy.models.GPRegression(X,y)\n",
    "m.optimize()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epsilon = 1.0\n",
    "delta = 0.01\n",
    "\n",
    "\n",
    "cv = 4\n",
    "p_grid = {\"lengthscale\":[], 'variance':[], 'noisevariance':[]}\n",
    "for ls in 5.0**np.linspace(2,4,2):\n",
    "    p_grid[\"lengthscale\"].append(ls)\n",
    "for v in 5.0**np.linspace(-1,3,2):\n",
    "    p_grid[\"variance\"].append(v)\n",
    "for nv in 5.0**np.linspace(0,2,2):\n",
    "    p_grid[\"noisevariance\"].append(nv)\n",
    "\n",
    "kf = KFold(n_splits=cv,shuffle=True,random_state=1)\n",
    "kern = GPy.kern.RBF(1)\n",
    "param_probabilities,temp_sens,sse_sens,temp_scores,scores,params,clf = dask_dp4gp.getprobabilities(X,y,p_grid,kf,ac_sens,kern=kern)\n",
    "\n",
    "print(\"PARAM PROBS\")\n",
    "print(param_probabilities)\n",
    "print(\"ALL SENSITIVITIES\")\n",
    "print(temp_sens)\n",
    "print(\"SENS\")\n",
    "print(sse_sens)\n",
    "print(\"ALL SCORES\")\n",
    "print(temp_scores)\n",
    "print(\"SCORES\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = None\n",
    "res = []\n",
    "currentres = -np.inf\n",
    "for s,p,prob in zip(scores,params,param_probabilities):\n",
    "    if p['lengthscale']!=current:\n",
    "        res.append(currentres)\n",
    "        currentres = -np.inf\n",
    "        current = p['lengthscale']\n",
    "    currentres=max(currentres,s)\n",
    "    \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
