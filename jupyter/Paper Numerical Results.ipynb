{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Numerical Results\n",
    "\n",
    "Step 1: Install DASK etc (follow instructions in Dask.ipynb)\n",
    "\n",
    "Step 2: Launch DASK server:\n",
    " \n",
    "    dask-ec2 up --keyname research --keypair .ssh/research.pem --region-name eu-west-1 --ami ami-d37961b5 --tags research:dp --count 4 --volume-size 30 --type c4.8xlarge\n",
    "\n",
    "Step 3: On the scheduler, run:\n",
    "\n",
    "    pip install git+https://github.com/lionfish0/dask_dp4gp.git\n",
    "    \n",
    "Step 4: On the scheduler, run this notebook. In particular run this cell once: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "runlist = ['pip install git+https://github.com/lionfish0/dask_dp4gp.git']\n",
    "\n",
    "for item in runlist:\n",
    "    print(\"Installing '%s' on workers...\" % item)\n",
    "    client.run(os.system,item)\n",
    "    print(\"Installing '%s' on scheduler...\" % item)\n",
    "    client.run_on_scheduler(os.system,item)\n",
    "    #os.system(item) #if you need to install it locally too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import dask_dp4gp\n",
    "\n",
    "dask_dp4gp.install_libraries_on_workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run the following analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0042492   0.02870927  0.2367837   0.69135983]\n",
      " [ 0.02662131  0.20103365  0.24542001  0.69299734]\n",
      " [ 0.048709    0.43837831  0.33126626  0.84603282]\n",
      " [ 0.08270285  0.48933589  0.38952283  1.31397035]\n",
      " [ 0.19239383  1.25068521  0.42003588  1.81254158]]\n",
      "[[  1.04379140e-03   9.39256749e-03   1.46038836e-01   5.91199594e-01]\n",
      " [  3.18851435e-02   2.20208406e-01   2.07628670e-01   6.29649828e-01]\n",
      " [  4.04117234e-02   3.34054795e-01   2.47510204e-01   7.13719276e-01]\n",
      " [  8.87866119e-02   7.84130685e-01   2.83409834e-01   1.04308255e+00]\n",
      " [  2.12443756e-01   1.12550033e+00   3.40077077e-01   1.86990344e+00]]\n",
      "[[  2.48378852e-04   1.82724148e-03   1.72865198e-01   5.04249809e-01]\n",
      " [  1.66914053e-02   1.26795300e-01   2.67845278e-01   6.64986382e-01]\n",
      " [  2.03271379e-02   1.66820512e-01   3.02653537e-01   7.56399727e-01]\n",
      " [  5.73889258e-02   3.80958199e-01   3.02935611e-01   9.89294247e-01]\n",
      " [  1.88143169e-01   1.21890455e+00   5.18963556e-01   2.39145729e+00]]\n",
      "[[ 0.24855971  0.24396606  0.29085648  0.21661775]\n",
      " [ 0.2605933   0.25024757  0.29076001  0.19839911]\n",
      " [ 0.28228353  0.27498419  0.28067312  0.16205917]]\n",
      "[[-0.41206854 -0.40353569 -0.35466892 -0.49566717]\n",
      " [-0.68753709 -0.68128438 -0.39573055 -5.77630937]\n",
      " [-1.77451281 -1.86681625 -1.53389898 -1.67499943]]\n",
      "[ 0.41140071  1.6107346   1.71623391]\n",
      "[ 0.41648508  1.88521535  1.71255687]\n"
     ]
    }
   ],
   "source": [
    "from dp4gp.utils import dp_normalise, dp_unnormalise\n",
    "from dp4gp import datasets\n",
    "from dask.distributed import Client\n",
    "from sklearn.model_selection import KFold\n",
    "import dask_dp4gp\n",
    "import numpy as np\n",
    "\n",
    "client = Client('127.0.0.1:8786')\n",
    "\n",
    "####Set up data and parameter search grid\n",
    "kung = datasets.load_kung()\n",
    "sensitivity = 100.0\n",
    "y,ac_sens,norm_params = dp_normalise(kung[kung[:,3]==0,0:1],sensitivity)\n",
    "X = kung[kung[:,3]==0,1:3]\n",
    "\n",
    "#todo these don't do anything - shift to get used a p_grid items\n",
    "epsilon = 1.0\n",
    "delta = 0.01\n",
    "cv = 3\n",
    "p_grid = {\"lengthscale\":[], 'variance':[]}#, 'noisevariance':[]}\n",
    "for ls in 5.0**np.arange(0,2):\n",
    "    p_grid[\"lengthscale\"].append(ls)\n",
    "for v in 5.0**np.arange(-1,1):\n",
    "    p_grid[\"variance\"].append(v)\n",
    "    \n",
    "####Get the -RMSE for each fold/param-combo\n",
    "scores = dask_dp4gp.getscores(X,y,p_grid,cv,ac_sens)\n",
    "\n",
    "kf = KFold(n_splits=cv)\n",
    "probabilities = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    probabilities.append(dask_dp4gp.getprobabilities(X_train,y_train,p_grid,5,ac_sens))\n",
    "    \n",
    "print(np.array(probabilities))\n",
    "print(scores)\n",
    "print(np.sum(probabilities*-scores,1))\n",
    "print(np.mean(-scores,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
